\documentclass{article}
\usepackage{arxiv}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{minted, xcolor}
\usemintedstyle{native}
\definecolor{bg}{HTML}{282828}
\setminted[python]{xleftmargin=0em, bgcolor=bg}
\setminted[console]{xleftmargin=0em, bgcolor=bg}
\setminted[json]{xleftmargin=0em, bgcolor=bg}
%\usepackage{graphicx} % Includegraphics
%usepackage{fancyvrb, color, graphicx, hyperref, amsmath, url}
%\usepackage{palatino}

<<echo=False>>=
import os
import sys
sys.path.append(os.getcwd())
from report_utils import *
@


\begin{document}

\title{Tropes in films: an initial analysis}

\author{Rubén Héctor García-Ortega\thanks{Badger Maps, Granada} \and Pablo García-Sánchez\thanks{Department of Computer Science and Engineering, University of C\'adiz} \and JJ Merelo\thanks{University of Granada}}
% Change Fergu's address - JJ
\maketitle

\begin{abstract}
TVTropes is a wiki that describes common tropes and which ones are used in which films. After releasing the TropeScraper Python module that extracts data from this site,
in this report use scraped information to statistically describe
    how tropes and films are related to each other and how this relations evolve in time.
    In order to do so, we generated a dataset through the tool TropeScraper in November 2019 and
    compared it to the latest snapshot of DBTropes, a dataset covering the same site and published in July 2019, providing descriptive analysis,
    studying the key differences between them and discussing the evolution of the wiki
    in terms of number of tropes, number of films and relations, to shed some light on how prevailing tropes evolve,
    which ones become more popular or fade away, and in general how a set of tropes represents a film and might be a key to its success.
    The results show that the number of tropes and films doubled their size and their relations, .... % Missing something here - JJ
    The dataset generated, the information extracted and the summaries provided are useful resources
    for any research involving films and tropes and they can provide proper context and explanations
    about the behaviour of models built on top of the dataset, including generation of new content or its use in machine learning.
\end{abstract}

{\bf Keywords}: Tropes; TvTropes; tropescraper.

\section{Motivations} \label{sec:problem}

Researches on story generation can benefit from having a recent \textit{corpus}
of tropes discovered in a generous amount film, % Rewrite, does not make sense of films? in films? - JJ
 actually, % Currently? - JJ
 as large as possible,
in a way that they can be efficiently processed and used in different experiments. % for doing what? - JJ
% Also: say briefly what's a trope - JJ

\begin{enumerate} % Not clear what you're enumerating here. If it's simply a set of arguments, you need to narrate them - JJ
\item There is a wiki called \textit{TV Tropes} that describes thousands
films and tropes, and has a prolific community that feeds the data.
\item A project called \textit{DBTropes} had the goal to extract n-tuples from TV Tropes so they can be automatically processed,
including, among much other interesting information, the tropes and the films.
\item DB Tropes was discontinued in 2016 and the latest snapshot of the dataset of n-tuples was built July 1st, 2016.
\item Recent publications still need to make use of the tropes by film and the latest dataset available is from 2016;
however, they would benefit from having updated information.
\item To fulfil the need of having an updated corpus of films and tropes,
in 2019 we developed a library called \textit{tropescraper} %link - JJ
 that:
    \begin{enumerate}
    \item can connect to the wiki TV Tropes,
    \item crawls through all the web pages of the films and extract their tropes,
    \item and returns a small dataset in a standard format.
    \end{enumerate}
\end{enumerate}

However, a basic statistical analysis shows that the data is incomplete, with distributions
that points out to huge biases due to the popularity of the films and tropes.
The detection of these biases is essential to build automatic learning models that work. % be more precise here
% Also, instead of "that work" I'd say "that can be explained". And use the example of number of tropes for old movies - JJ

Furthermore, before the existence of TropeScraper,
the scientific researches are based on the dataset DBTropes (2016).
It makes us wonder how much the information about films and tropes from TVTropes has changed since then.
How much has it grown? How have the most used tropes changes since then? And the best described films in terms of tropes?
How has the graph of connections between tropes and films evolved through time?
The answers to these questions can be the key to improve some researches and predict how
the current dynamics of the TV Tropes community can affect future data.

\section{Analysis of the generated dataset} \label{sec:tools}

The relation between tropes and films can be studied from both perspectives.

\subsection{Descriptive analysis of the films by the number of tropes}

According to Figure~\ref{fig:decriptive_analysis_tropes_by_film}, the dataset in November 2019
contains 12147 films,
and the average number of tropes by film is 54.242, but the film with the most tropes in the dataset has 971.
If we compare these values against the data in 2016, the number of films is almost the double,
and the average number of tropes per film as well. In other words, the dataset has more films and the films contain
more tropes. % This means that... - JJ

\begin{figure}[htpb]
\center
<<echo=False,results="tex", width="12cm">>=
describe_tropes()
@
\caption{Descriptive analysis comparison of trope occurrences by film in July 2016 vs November 2019}
\label{fig:decriptive_analysis_tropes_by_film}
\end{figure}

The figure~\ref{fig:boxplot_tropes_by_film} shows the boxplots comparison of the two datasets. As we can see,
TV Tropes tends to have a better description of the films in terms of tropes and less films with no tropes,
that is reflected in a interquartile range displaced to the top and shorter.

\begin{figure}[htpb]
\center
<<echo=False,fig=True, width="10cm", f_pos="h", f_size=(9,2)>>=
boxplot_tropes()
@
\caption{Boxplots comparison of trope occurrences by film in July 2016 vs November 2019}
\label{fig:boxplot_tropes_by_film}
\end{figure}


In figure~\ref{fig:frequency_tropes_by_film}, we can observe the number of films that have a specific number of tropes.
As we can observe, the new dataset has been displaced to the right with respect to the number of tropes in the film,
that means that films are better described. Previously, most of the films had just 1 trope and currently, most of them
have between 10 and 100.

\begin{figure}[htpb]
\center
<<echo=False,fig=True, width="10cm", f_pos="h", f_size=(9,6)>>=
frequencies_tropes()
@
\caption{Boxplots comparison of trope occurrences by film in July 2016 vs November 2019}
\label{fig:frequency_tropes_by_film}
\end{figure}

When we compare the top films by number of tropes in July 2016 vs November 2019,
as shown in figure~\ref{fig:top_films_by_number_of_tropes}, 17 films our of 50 are shared in the lists.
It is interesting to point out that, although both lists have similar number of tropes in the highest values,
the top films of the new dataset almost double the number of tropes in the old one, in the lower values of the list.

\begin{figure}[htpb]
\center
<<echo=False,results="tex", width="12cm">>=
top_films_by_number_of_tropes(50)
@
\caption{Top 50 films by number of tropes in July 2016 vs November 2019. Common elements are marked in blue.}
\label{fig:top_films_by_number_of_tropes}
\end{figure}








\subsection{Descriptive analysis of the tropes by the number of films}

According to Figure~\ref{fig:decriptive_analysis_films_by_trope}. The dataset in November 2019
contains 26479 tropes,
and the average number of films by trope is 24.883, but the trope that appear in the most films in the dataset has 3386 films.
If we compare these values against the data in 2016, the number of tropes is 3/2 of the old dataset,
but the average number of films where a trope appears has tripled the old value.
In other words, the dataset has more tropes (about 50\% more) and, on average, the tropes are present in
more films.

\begin{figure}[htpb]
\center
<<echo=False,results="tex", width="12cm">>=
describe_films()
@
\caption{Descriptive analysis comparison of trope occurrences by film in July 2016 vs November 2019}
\label{fig:decriptive_analysis_films_by_trope}
\end{figure}

However, as we can observe in figure~\ref{fig:boxplot_films_by_trope}, a bigger average does not mean that tropes
are more widely used among films. As we can observe, the interquartile range in 2019 for the use of tropes
begins from 1 and is wider, in other words, we have a similar frequency but amplified with more tropes.

\begin{figure}[htpb]
\center
<<echo=False,fig=True, width="10cm", f_pos="h", f_size=(9,2)>>=
boxplot_films()
@
\caption{Boxplots comparison of trope occurrences by film in July 2016 vs November 2019}
\label{fig:boxplot_films_by_trope}
\end{figure}

This effect is clearly visible in Figure~\ref{fig:frequency_films_by_trope}.
Just one film per trope is still the most common frequency, and this effect has been
% But the difference between that and the second is bigger? The "fat tail" effect is clearer? - JJ
amplified in the new dataset, showing less curvature for the new dataset.

\begin{figure}[htpb]
\center
<<echo=False,fig=True, width="10cm", f_pos="h", f_size=(9,6)>>=
frequencies_films()
@
\caption{Boxplots comparison of trope occurrences by film in July 2016 vs November 2019}
\label{fig:frequency_films_by_trope}
\end{figure}

When we compare the top tropes by number of uses in films in July 2016 vs November 2019,
as shown in figure~\ref{fig:top_tropes_by_number_of_films}, it looks completely different to the analogous analysis for films:
in this case, there are no common tropes in the top lists for both datasets.
Also, the difference between the top trope is huge, and the new top trope is used around 7 times more than the old top.

\begin{figure}[htpb]
\center
<<echo=False,results="tex", width="12cm">>=
top_tropes_by_number_of_films(50)
@
\caption{Top 50 films by number of tropes in July 2016 vs November 2019. Common elements are marked in blue.}
\label{fig:top_tropes_by_number_of_films}
\end{figure}

\section{Conclusions}

TV Tropes has grown from July 2016 to November 2019, in terms of films and tropes:
in November 2019 there are almost twice the number of films and almost 3/2 of the tropes.
However, the relations between films and tropes has not grown the same way.


If we look at the films, there are more films, and in general, films are better described in terms of tropes.
In 3 years, the top list has changed, but not drastically, and we can see that 1/3 of the films in the top 50 are still in the top 50,
but, in general with twice the number of tropes. So, more films in the database and the existing films are better described.

If we look at the tropes, things are different. Tropes are added in a lower proportion but are the ones mostly used since 2016,
in other words, new tropes have been widely discovered in films, but not many old tropes have been newly found in the films.
This is specially visible in the top 50, where no trope is shared at all. More than this, all the tropes in the top 50 in November 2019
are present in more films than all the tropes in July 2016.

We could say that old popular tropes haven't been explored as much as new tropes, but old popular films have still been reviewed a lot.
% What does it say about the bias? How's this interesting for machine learning with this? - JJ

\section*{Acknowledgements}
This work has been partially funded by projects DeepBio (TIN2017-85727-C4-2-P) and TEC2015-68752
and ``Ayuda del Programa de Fomento e Impulso de la actividad Investigadora de la Universidad de C\'adiz''.

\section{Bibliography}
\bibliographystyle{abbrv}
\bibliography{report}

\end{document}
